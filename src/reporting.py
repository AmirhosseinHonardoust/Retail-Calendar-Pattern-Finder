from __future__ import annotations

import os
import textwrap
import pandas as pd

def write_markdown_report(
    path: str,
    dataset_profile: dict,
    dow_summary: pd.DataFrame,
    month_summary: pd.DataFrame,
    top_spikes: pd.DataFrame,
    figure_paths: dict,
) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)

    def fmt_money(x):
        try:
            return f"{float(x):,.0f}"
        except Exception:
            return str(x)

    best_dow = dow_summary.sort_values("avg_daily_revenue", ascending=False).iloc[0]
    best_month = month_summary.sort_values("revenue", ascending=False).iloc[0]
    worst_month = month_summary.sort_values("revenue", ascending=True).iloc[0]

    spikes_tbl = top_spikes.copy()
    spikes_tbl["date"] = spikes_tbl["date"].dt.strftime("%Y-%m-%d")
    spikes_tbl["revenue"] = spikes_tbl["revenue"].map(fmt_money)
    spikes_tbl["expected_revenue"] = spikes_tbl["expected_revenue"].map(fmt_money)
    spikes_tbl["residual"] = spikes_tbl["residual"].map(lambda x: fmt_money(x))
    spikes_tbl["robust_z_residual"] = spikes_tbl["robust_z_residual"].map(lambda x: f"{x:.2f}")
    spikes_tbl = spikes_tbl[["date","dow","revenue","expected_revenue","residual","robust_z_residual"]]

    md = f"""\
# Retail Calendar Pattern Finder, Insights Report

## Dataset profile
- Rows: **{dataset_profile['n_rows']:,}**
- Date range: **{dataset_profile['date_min']} → {dataset_profile['date_max']}**
- Observed transaction-days: **{dataset_profile['n_days']:,}**
- Categories: **{", ".join(dataset_profile['categories'])}**
- Total-amount identity mismatches: **{dataset_profile.get('total_amount_mismatches', 0)}**
- Note: Missing calendar dates are **unknown coverage**, not necessarily zero sales.

## Seasonality summary

### Day-of-week
- Best average day: **{best_dow['dow']}** (avg daily revenue ≈ **{fmt_money(best_dow['avg_daily_revenue'])}**)
- Median daily revenue on that day ≈ **{fmt_money(best_dow['median_daily_revenue'])}**
- Observed days for that DOW: **{int(best_dow['n_days'])}**

![Daily revenue by day-of-week]({figure_paths['dow_revenue']})

### Month
- Strongest month (by total revenue): **{best_month['month']}** (≈ **{fmt_money(best_month['revenue'])}** across **{int(best_month['n_days'])}** observed days)
- Weakest month (by total revenue): **{worst_month['month']}** (≈ **{fmt_money(worst_month['revenue'])}** across **{int(worst_month['n_days'])}** observed days)
- Reminder: if the last month is partial (few days), treat with caution.

![Monthly revenue]({figure_paths['month_revenue']})

### Calendar heatmap (month × day-of-week)
![Heatmap]({figure_paths['heatmap']})

## Event-like spike days
Spikes are detected using:
1) **Robust z-score** on daily revenue using MAD
2) **Residual spikes** vs a simple seasonal baseline (month+dow → month → dow → overall)

### Top spike days (by residual z-score)
{spikes_tbl.to_markdown(index=False)}

![Spike scatter]({figure_paths['spike_scatter']})

## Recommendations / hypotheses to test
- Staff and inventory planning should prioritize historically strong days while monitoring for residual spikes.
- When a spike is detected, investigate **category mix shifts** first (many spikes are driven by one category dominating the day).
- Add a “coverage warning” in dashboards: missing dates in the dataset are not confirmed zero-sales days.

---
Generated by `python -m src.pipeline`
"""

    with open(path, "w", encoding="utf-8") as f:
        f.write(textwrap.dedent(md))
